# AI Hello Starters â€“ Multi-Provider Quick Start

This bundle includes **five** self-contained â€œHello, World!â€ starters so participants can choose any AI platform for the workshop.

## ğŸ“¦ Whatâ€™s Inside

- **openai_hello/** â€” OpenAI SDK (uses `OPENAI_API_KEY`)
- **gemini_hello/** â€” Google Gemini (uses `GOOGLE_API_KEY`)
- **huggingface_hello/** â€” Hugging Face Inference API (uses `HUGGINGFACE_API_KEY`)
- **lmstudio_hello/** â€” LM Studio local server (OpenAI-compatible, no cloud key)
- **ollama_hello/** â€” Ollama local model runner (no Python deps, no cloud key)

Each folder contains:
- `hello_world_ai.py` â€” minimal runnable example
- `requirements.txt` â€” exact dependencies
- `README.md` â€” setup & run steps

---

## ğŸš€ Quick Start (Pick One Path)

### 1) OpenAI (cloud)
- Set: `OPENAI_API_KEY`
- Install: `pip install -r openai_hello/requirements.txt`
- Run: `python openai_hello/hello_world_ai.py`

### 2) Google Gemini (cloud)
- Set: `GOOGLE_API_KEY`
- Install: `pip install -r gemini_hello/requirements.txt`
- Run: `python gemini_hello/hello_world_ai.py`

### 3) Hugging Face Inference API (cloud)
- Set: `HUGGINGFACE_API_KEY`
- Install: `pip install -r huggingface_hello/requirements.txt`
- Run: `python huggingface_hello/hello_world_ai.py`

### 4) LM Studio (local)
- In LM Studio: download a chat model â†’ enable **Local Server** (http://localhost:1234/v1)
- Install: `pip install -r lmstudio_hello/requirements.txt`
- Run: `python lmstudio_hello/hello_world_ai.py`

### 5) Ollama (local)
- Install Ollama â†’ `ollama run llama3` (first-time model pull)
- No Python deps required
- Run: `python ollama_hello/hello_world_ai.py`

---

## ğŸ†“ Free vs Local Considerations

| Platform | Needs Internet? | Free Tier | Notes |
|---------|------------------|----------|------|
| OpenAI | âœ… | Trial credits (not guaranteed) | Industry standard SDK & models |
| Google Gemini | âœ… | ~1,500 req/day | Great free quota for workshops |
| Hugging Face | âœ… | ~30k input tokens/mo | Many models, simple client |
| LM Studio | âŒ (after download) | Local | OpenAI-compatible local server |
| Ollama | âŒ (after install) | Local | Fast CLI, very simple to script |

> Tip: If budget or network is a concern, start with **Ollama** or **LM Studio**.

---

## ğŸ”‘ Environment Variable Names (cloud options)

- OpenAI â†’ `OPENAI_API_KEY`
- Google Gemini â†’ `GOOGLE_API_KEY`
- Hugging Face â†’ `HUGGINGFACE_API_KEY`

On Windows (PowerShell):
```powershell
setx NAME "value"
# restart terminal after setting
```

On macOS/Linux (bash/zsh):
```bash
export NAME="value"
# add to ~/.bashrc or ~/.zshrc to persist
```

---

## â— Troubleshooting

- `ModuleNotFoundError` â†’ Install requirements from the correct folder.
- â€œAPI key not setâ€ â†’ Export the right env var name for your chosen path.
- LM Studio connection errors â†’ Verify **Local Server** is enabled and the model is running.
- Ollama errors â†’ Run `ollama run llama3` once to pull the model locally, then re-run the script.

Happy hacking! âœ¨
